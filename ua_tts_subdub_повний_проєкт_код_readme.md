# UA-TTS-Subdub

–£–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω–∏–π –æ—Ñ–ª–∞–π–Ω TTS-–∫–æ–Ω–≤–µ—î—Ä –Ω–∞ –±–∞–∑—ñ **StyleTTS2** –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é **–≤–µ—Ä–±–∞–ª—ñ–∑–∞—Ü—ñ—ó**, **–Ω–∞–≥–æ–ª–æ—Å—ñ–≤** —ñ **–ø–æ–≤–Ω–æ—ó –æ–∑–≤—É—á–∫–∏ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤ SRT** –∑ —Ç–æ—á–Ω–∏–º –¥–æ—Ç—Ä–∏–º–∞–Ω–Ω—è–º —Ç–∞–π–º—ñ–Ω–≥—ñ–≤ (–∑ –æ–ø—Ü—ñ–π–Ω–∏–º time‚Äëstretch).

---

## üì¶ –ú–æ–∂–ª–∏–≤–æ—Å—Ç—ñ
- üó£Ô∏è **–¢–µ–∫—Å—Ç ‚Üí –ú–æ–≤–∞** (single/multi‚Äëspeaker StyleTTS2).
- üî§ **–í–µ—Ä–±–∞–ª—ñ–∑–∞—Ü—ñ—è** —á–∏—Å–µ–ª, –¥–∞—Ç, —Å–∫–æ—Ä–æ—á–µ–Ω—å (–æ—Ñ–ª–∞–π–Ω mBART).
- ‚óåÃÅ **–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω—ñ –Ω–∞–≥–æ–ª–æ—Å–∏** (–∞–∫—Ü–µ–Ω—Ç–∞—Ç–æ—Ä) + –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –¥–æ **IPA**.
- üé¨ **–û–∑–≤—É—á–∫–∞ SRT-—Å—É–±—Ç–∏—Ç—Ä—ñ–≤**: –∫–æ–∂–Ω–∞ —Ä–µ–ø–ª—ñ–∫–∞ —Å–∏–Ω—Ç–µ–∑—É—î—Ç—å—Å—è —Ç–∞ **–ø—ñ–¥–≥–∞–Ω—è—î—Ç—å—Å—è —É —á–∞—Å** –ø—ñ–¥ `start ‚Üí end` (time‚Äëstretch).
- üìÅ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É —É `outputs/‚Ä¶ .wav`.
- üåê –ì–æ—Ç–æ–≤–µ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫—É –π **Hugging Face Spaces**.

---

## üóÇÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ—î–∫—Ç—É
```
UA-TTS-Subdub/
‚îú‚îÄ app.py                         # –ì–æ–ª–æ–≤–Ω–∏–π Gradio –∑–∞—Å—Ç–æ—Å—É–Ω–æ–∫
‚îú‚îÄ verbalizer.py                  # –û–±–≥–æ—Ä—Ç–∫–∞ –Ω–∞–¥ mBART –≤–µ—Ä–±–∞–ª—ñ–∑–∞—Ç–æ—Ä–æ–º
‚îú‚îÄ ipa_uk.py                      # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç—É —É IPA (–∞–¥–∞–ø—Ç–∏–≤–Ω–∏–π –º–æ–¥—É–ª—å)
‚îú‚îÄ utils/
‚îÇ  ‚îú‚îÄ audio.py                    # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è, –∑–∞–ø–∏—Å, —Ç–∏—à–∞, time-stretch
‚îÇ  ‚îî‚îÄ text.py                     # –†–æ–∑–±–∏—Ç—Ç—è —Ç–µ–∫—Å—Ç—É, —á–∏—Å—Ç–∫–∞ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤
‚îú‚îÄ scripts/
‚îÇ  ‚îî‚îÄ download_models.py          # (–û–ø—Ü—ñ–π–Ω–æ) –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π —É –ª–æ–∫–∞–ª—å–Ω—ñ –ø–∞–ø–∫–∏
‚îú‚îÄ requirements.txt               # –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ Python
‚îú‚îÄ README.md                      # –¶–µ–π —Ñ–∞–π–ª (—Å–∫–æ—Ä–æ—á–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è)
‚îú‚îÄ .gitignore
‚îú‚îÄ voices/                        # –¢—É—Ç *.pt —Å—Ç–∏–ª—ñ –¥–ª—è multi-speaker –º–æ–¥–µ–ª—ñ
‚îÇ  ‚îî‚îÄ README.md
‚îú‚îÄ outputs/                       # –ó–±–µ—Ä–µ–∂–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ (.wav)
‚îî‚îÄ models/
   ‚îú‚îÄ models--verbalizer/         # –õ–æ–∫–∞–ª—å–Ω–∞ –ø–∞–ø–∫–∞ –≤–µ—Ä–±–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ (HF snapshot)
   ‚îú‚îÄ models--styletts2-single/   # –õ–æ–∫–∞–ª—å–Ω–∞ –ø–∞–ø–∫–∞ single‚Äëspeaker –º–æ–¥–µ–ª—ñ
   ‚îî‚îÄ models--styletts2-multi/    # –õ–æ–∫–∞–ª—å–Ω–∞ –ø–∞–ø–∫–∞ multi‚Äëspeaker –º–æ–¥–µ–ª—ñ
```

> **–ü—Ä–∏–º—ñ—Ç–∫–∞:** –Ω–∞–∑–≤–∏ –ø—ñ–¥–ø–∞–ø–æ–∫ —É `models/` –≤—ñ–ª—å–Ω—ñ ‚Äî –≥–æ–ª–æ–≤–Ω–µ —É–∑–≥–æ–¥–∏—Ç–∏ —ó—Ö —É `app.py`.

---

## üîß –í—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—è

1) **Python 3.10‚Äì3.11**, `ffmpeg` (–¥–ª—è –¥–µ—è–∫–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫ –∞—É–¥—ñ–æ ‚Äî –Ω–µ –æ–±–æ–≤ º—è–∑–∫–æ–≤–æ, –∞–ª–µ –±–∞–∂–∞–Ω–æ)

2) –í—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ:
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt
```

3) **–ú–æ–¥–µ–ª—ñ (–æ—Ñ–ª–∞–π–Ω):**
- –ü—ñ–¥–≥–æ—Ç—É–π—Ç–µ –ª–æ–∫–∞–ª—å–Ω—ñ –ø–∞–ø–∫–∏ –∑ –º–æ–¥–µ–ª—è–º–∏ (–±—É–¥—å-—è–∫–∏–º —Å–ø–æ—Å–æ–±–æ–º):
  - –í–µ—Ä–±–∞–ª—ñ–∑–∞—Ç–æ—Ä mBART ‚Üí `models/models--verbalizer`
  - StyleTTS2 (single) ‚Üí `models/models--styletts2-single`
  - StyleTTS2 (multi) ‚Üí `models/models--styletts2-multi`
- (–û–ø—Ü—ñ–π–Ω–æ) —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—å —Å–∫—Ä–∏–ø—Ç–æ–º:
```bash
python scripts/download_models.py
```

4) **–ì–æ–ª–æ—Å–∏ (multi‚Äëspeaker):**
- –ü–æ–∫–ª–∞–¥—ñ—Ç—å —Å—Ç–∏–ª—ñ `.pt` —É `voices/` (–¥–∏–≤. `voices/README.md`).

---

## üöÄ –ó–∞–ø—É—Å–∫
```bash
python app.py
```
–í—ñ–¥–∫—Ä–∏–π—Ç–µ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å: `http://127.0.0.1:7860`.

### –†–µ–∂–∏–º–∏
- **–¢–µ–∫—Å—Ç ‚Üí –ú–æ–≤–∞**: –≤–≤–µ–¥—ñ—Ç—å —Ç–µ–∫—Å—Ç, –æ–±–µ—Ä—ñ—Ç—å –º–æ–¥–µ–ª—å (single/multi), –≥–æ–ª–æ—Å —ñ —à–≤–∏–¥–∫—ñ—Å—Ç—å.
- **–û–∑–≤—É—á–∫–∞ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤**: –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ `.srt` ‚Üí –æ—Ç—Ä–∏–º–∞—î—Ç–µ **–ø–æ–≤–Ω–∏–π .wav** –∑ –¥–æ—Ç—Ä–∏–º–∞–Ω–Ω—è–º —Ç–∞–π–º—ñ–Ω–≥—ñ–≤; —Ñ–∞–π–ª —Ç–∞–∫–æ–∂ –∑–±–µ—Ä–µ–∂–µ—Ç—å—Å—è –≤ `outputs/`.

---

## üß† –õ–æ–≥—ñ–∫–∞ –∫–æ–Ω–≤–µ—î—Ä–∞
1. **–í–µ—Ä–±–∞–ª—ñ–∑–∞—Ü—ñ—è**: —Ä–æ–∑–∫—Ä–∏—Ç—Ç—è —á–∏—Å–µ–ª/–¥–∞—Ç/—Å–∫–æ—Ä–æ—á–µ–Ω—å ‚Üí —á–∏—Å—Ç–∏–π —Ç–µ–∫—Å—Ç.
2. **–ê–∫—Ü–µ–Ω—Ç–∞—Ç–æ—Ä**: —Ä–æ–∑—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞–≥–æ–ª–æ—Å—ñ–≤, –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è Unicode, —É–Ω—ñ—Ñ—ñ–∫–∞—Ü—ñ—è —Ç–∏—Ä–µ.
3. **G2P/IPA**: –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –Ω–∞–≥–æ–ª–æ—à–µ–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç—É —É —Ñ–æ–Ω–µ–º–∏.
4. **StyleTTS2**: —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—è —Ñ–æ–Ω–µ–º ‚Üí –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è –∑–≤—É–∫—É (24 –∫–ì—Ü).
5. **Subdub (SRT)**: –¥–ª—è –∫–æ–∂–Ω–æ—ó —Ä–µ–ø–ª—ñ–∫–∏ –≥–µ–Ω–µ—Ä—É—î—Ç—å—Å—è –∞—É–¥—ñ–æ —ñ **time‚Äëstretch** –ø—ñ–¥ `duration = end ‚àí start`; –º—ñ–∂ —Ä–µ–ø–ª—ñ–∫–∞–º–∏ –¥–æ–¥–∞—î—Ç—å—Å—è —Ç–∏—à–∞ –∞–±–æ –≤—Ä–∞—Ö–æ–≤—É—î—Ç—å—Å—è –ø–µ—Ä–µ—Ç–∏–Ω.

---

## ‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —à–ª—è—Ö—ñ–≤ –º–æ–¥–µ–ª–µ–π —É `app.py`
–£ –≤–µ—Ä—Ö–Ω—ñ–π —á–∞—Å—Ç–∏–Ω—ñ `app.py` –≤—ñ–¥–∫–æ—Ä–∏–≥—É–π—Ç–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏:
```python
VERBALIZER_DIR = 'models/models--verbalizer'
STYLETTS2_SINGLE_DIR = 'models/models--styletts2-single'
STYLETTS2_MULTI_DIR = 'models/models--styletts2-multi'
PROMPTS_DIR = 'voices'
SAMPLE_RATE = 24000
```

---

## üìÅ voices/README.md
```
# –ì–æ–ª–æ—Å–∏ –¥–ª—è multi-speaker

–ü–æ–∫–ª–∞–¥—ñ—Ç—å —Å—é–¥–∏ —Ñ–∞–π–ª–∏ —Å—Ç–∏–ª—ñ–≤ *.pt, –Ω–∞–∑–≤–∞ —Ñ–∞–π–ª—É = –Ω–∞–∑–≤–∞ –≥–æ–ª–æ—Å—É.
–ù–∞–ø—Ä.:  
voices/
  ‚îú‚îÄ filatov.pt
  ‚îú‚îÄ mariya.pt
  ‚îî‚îÄ narrator.pt

–Ø–∫—â–æ —É –≤–∞—Å –æ–¥–∏–Ω –≥–æ–ª–æ—Å (single), —Ü—è –ø–∞–ø–∫–∞ –º–æ–∂–µ –±—É—Ç–∏ –ø–æ—Ä–æ–∂–Ω—å–æ—é.
```

---

## üß© requirements.txt
```
accelerate>=0.33.0
transformers>=4.42.0
huggingface_hub>=0.24.0
torch>=2.1.0
numpy>=1.26.0
gradio>=4.44.0
spaces>=0.29.0
soundfile>=0.12.1
librosa>=0.10.1
srt>=3.5.3
unicodedata2>=15.1.0
ukrainian-word-stress>=1.5.0
# –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å—É StyleTTS2 (–æ–ø—É–±–ª—ñ–∫—É–π—Ç–µ –≤–ª–∞—Å–Ω–∏–π –ø–∞–∫–µ—Ç –∞–±–æ –ª–æ–∫–∞–ª—å–Ω–∏–π –º–æ–¥—É–ª—å)
styletts2-inference @ git+https://github.com/patriotyk/styletts2_ukrainian_inference.git
```
> –ó–∞ –ø–æ—Ç—Ä–µ–±–∏ –∑–∞–º—ñ–Ω—ñ—Ç—å –æ—Å—Ç–∞–Ω–Ω—ñ–π —Ä—è–¥–æ–∫ –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏–π —à–ª—è—Ö/—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ–π –≤–∞—à–æ–≥–æ —ñ–Ω—Ñ–µ—Ä–µ–Ω—Å‚Äë–ø–∞–∫–µ—Ç–∞.

---

## üìò –ö–æ–¥ —Ñ–∞–π–ª—ñ–≤

### `verbalizer.py`
```python
import torch
from transformers import AutoModelForSeq2SeqLM, MBartTokenizer

class Verbalizer:
    """–û–±–≥–æ—Ä—Ç–∫–∞ –Ω–∞–≤–∫–æ–ª–æ mBART-–≤–µ—Ä–±–∞–ª—ñ–∑–∞—Ç–æ—Ä–∞ –¥–ª—è –æ—Ñ–ª–∞–π–Ω-—Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è."""
    def __init__(self, model_path: str, device: str = 'cpu'):
        try:
            self.tokenizer = MBartTokenizer.from_pretrained(
                model_path,
                local_files_only=True
            )
            self.model = AutoModelForSeq2SeqLM.from_pretrained(
                model_path,
                local_files_only=True
            )
        except Exception as e:
            print(f"[Verbalizer] –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ: {e}")
            raise
        self.to(device)

    def to(self, device: str):
        self.device = device
        self.model.to(self.device)

    @torch.inference_mode()
    def generate_text(self, text: str, **gen_kwargs) -> str:
        inputs = self.tokenizer(text, return_tensors="pt").to(self.device)
        out = self.model.generate(**inputs, **gen_kwargs)
        decoded = [self.tokenizer.decode(t, skip_special_tokens=True) for t in out]
        return decoded[0] if decoded else ""
```

### `ipa_uk.py`
```python
"""
–ê–¥–∞–ø—Ç–∏–≤–Ω–∏–π –ø–µ—Ä–µ—Ç–≤–æ—Ä—é–≤–∞—á —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç—É —É IPA.
–ü—Ä—ñ–æ—Ä–∏—Ç–µ—Ç–∏:
1) –Ø–∫—â–æ –¥–æ—Å—Ç—É–ø–Ω–∞ —Å—Ç–æ—Ä–æ–Ω–Ω—è –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ (–Ω–∞–ø—Ä., uk-g2p / –≤–ª–∞—Å–Ω–∏–π –º–æ–¥—É–ª—å), –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —ó—ó.
2) –Ü–Ω–∞–∫—à–µ ‚Äî —Å–ø—Ä–æ—â–µ–Ω–∏–π —Ç—Ä–∞–Ω—Å–ª—ñ—Ç —É –Ω–∞–±—ñ—Ä —Ñ–æ–Ω–µ–º, —Å—É–º—ñ—Å–Ω–∏–π —ñ–∑ —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ç–æ—Ä–æ–º –º–æ–¥–µ–ª—ñ.

–£ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—ñ –∑–∞–º—ñ–Ω—ñ—Ç—å —Ü–µ–π —Ñ–∞–π–ª –Ω–∞ –≤–∞—à —Ç–æ—á–Ω–∏–π G2P.
"""
import re

# –°—Ç—Ä–µ—Å-—Å–∏–º–≤–æ–ª (–∫–æ–º–±—ñ–Ω—É—é—á–∏–π –≥–æ—Å—Ç—Ä–∏–π –Ω–∞–≥–æ–ª–æ—Å)
STRESS = "\u0301"

try:
    # –ü—Ä–∏–∫–ª–∞–¥: –≤–∞—à —Ç–æ—á–Ω–∏–π –º–æ–¥—É–ª—å
    from uk_g2p import g2p as _precise_g2p  # type: ignore
except Exception:  # noqa: E722
    _precise_g2p = None

_basic_map = {
    '–∞': 'a', '–±': 'b', '–≤': 'v', '–≥': '…¶', '“ë': 'g', '–¥': 'd', '–µ': 'e', '—î': 'je',
    '–∂': ' í', '–∑': 'z', '–∏': '…™', '—ñ': 'i', '—ó': 'ji', '–π': 'j', '–∫': 'k', '–ª': 'l',
    '–º': 'm', '–Ω': 'n', '–æ': 'o', '–ø': 'p', '—Ä': 'r', '—Å': 's', '—Ç': 't', '—É': 'u',
    '—Ñ': 'f', '—Ö': 'x', '—Ü': 'ts', '—á': 't É', '—à': ' É', '—â': ' Ét É', '—å': '', "'": '',
    '—é': 'ju', '—è': 'ja',
}

_vowel = set("–∞–µ—î–∏—ñ—î—ó–æ—É—é—èAE–Ñ–ò–Ü–á–á–û–£–Æ–Ø")


def _simple_ipa(text: str) -> str:
    t = text.lower()
    # –ø—Ä–∏–±–∏—Ä–∞—î–º–æ —Ç–µ–≥–æ–≤—ñ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∏
    t = re.sub(r"<[^>]+>", "", t)
    out = []
    for ch in t:
        out.append(_basic_map.get(ch, ch))
    ipa = " ".join(out)
    # –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –ø–æ–∑–∏—Ü—ñ—é –Ω–∞–≥–æ–ª–æ—Å—É —è–∫ –æ–∫—Ä–µ–º–∏–π —Å–∏–º–≤–æ–ª —É —Å—Ç—Ä—ñ–º—ñ
    ipa = ipa.replace(STRESS, STRESS)
    return ipa


def ipa(text: str) -> str:
    if _precise_g2p is not None:
        try:
            return _precise_g2p(text)
        except Exception:
            pass
    return _simple_ipa(text)
```

### `utils/audio.py`
```python
from __future__ import annotations
import os
from datetime import datetime
import numpy as np
import soundfile as sf
import librosa
import torch


def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)


def save_wav(np_audio: np.ndarray, sr: int, out_dir: str, base: str) -> str:
    ensure_dir(out_dir)
    ts = datetime.now().strftime('%Y%m%d__%H%M%S')
    path = os.path.join(out_dir, f"{base}__{ts}.wav")
    sf.write(path, np_audio, sr)
    return path


def make_silence(seconds: float, sr: int) -> torch.Tensor:
    n = max(0, int(round(seconds * sr)))
    return torch.zeros(n, dtype=torch.float32)


def normalize_audio(wav: torch.Tensor, peak: float = 0.95) -> torch.Tensor:
    if wav.numel() == 0:
        return wav
    m = wav.abs().max().item()
    if m == 0:
        return wav
    scale = min(1.0, peak / m)
    return wav * scale


def time_stretch_to_duration(np_audio: np.ndarray, sr: int, target_sec: float, clamp: tuple[float, float] = (0.6, 1.6)) -> np.ndarray:
    """
    –ü—ñ–¥–≥–∞–Ω—è—î –¥–æ–≤–∂–∏–Ω—É —Å–∏–≥–Ω–∞–ª—É –ø—ñ–¥ target_sec –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é phase-vocoder (librosa.effects.time_stretch).
    rate > 1 ‚Üí —à–≤–∏–¥—à–µ (–∫–æ—Ä–æ—Ç—à–µ); output_len = input_len / rate.
    """
    if target_sec <= 0:
        return np_audio
    in_sec = len(np_audio) / sr
    if in_sec == 0:
        return np_audio
    rate = max(clamp[0], min(clamp[1], in_sec / target_sec))
    if abs(rate - 1.0) < 1e-3:
        return np_audio
    y = librosa.effects.time_stretch(np_audio.astype('float32'), rate=rate)
    # –í–∏—Ä—ñ–≤–Ω—é–≤–∞–Ω–Ω—è –¥–æ —Ç–æ—á–Ω–æ—ó –¥–æ–≤–∂–∏–Ω–∏
    out_len = int(round(target_sec * sr))
    if len(y) < out_len:
        pad = out_len - len(y)
        y = np.pad(y, (0, pad))
    elif len(y) > out_len:
        y = y[:out_len]
    return y.astype('float32')
```

### `utils/text.py`
```python
import re
from unicodedata import normalize
from ukrainian_word_stress import Stressifier, StressSymbol

stressifier = Stressifier()

SPLIT_SYMBOLS = '.?!:'

def split_to_parts(text: str, max_len: int = 150) -> list[str]:
    parts = ['']
    idx = 0
    for s in text:
        parts[idx] += s
        if s in SPLIT_SYMBOLS and len(parts[idx]) > max_len:
            idx += 1
            parts.append('')
    return [p for p in parts if p.strip()]


def clean_and_stress(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è + –∑–∞–º—ñ–Ω–∞ '+' –Ω–∞ –Ω–∞–≥–æ–ª–æ—Å + —É–Ω—ñ—Ñ—ñ–∫–∞—Ü—ñ—è —Ç–∏—Ä–µ + stressifier."""
    t = (text or '').strip()
    t = t.replace('+', StressSymbol.CombiningAcuteAccent)
    t = normalize('NFKC', t)
    t = re.sub(r'[·†Ü‚Äê‚Äë‚Äí‚Äì‚Äî‚Äï‚Åª‚Çã‚àí‚∏∫‚∏ª]', '-', t)
    t = re.sub(r' - ', ': ', t)
    return stressifier(t)


def clean_sub_text(raw: str) -> str:
    # –ø—Ä–∏–±–∏—Ä–∞—î–º–æ HTML/ASS —Ç–µ–≥–∏, –ø–µ—Ä–µ–Ω–æ—Å —Ä—è–¥–∫—ñ–≤, –∫—É—Ä—Å–∏–≤–∏ —Ç–æ—â–æ
    t = re.sub(r'<[^>]+>', '', raw)
    t = re.sub(r'\{\\[^}]+\}', '', t)  # {\i1} —ñ –ø–æ–¥—ñ–±–Ω—ñ
    t = t.replace('\n', ' ').replace('\r', ' ')
    t = re.sub(r'\s+', ' ', t)
    return t.strip()
```

### `scripts/download_models.py`
```python
"""
–ó—Ä–∞–∑–∫–æ–≤–∏–π —Å–∫—Ä–∏–ø—Ç –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π —É –ª–æ–∫–∞–ª—å–Ω—ñ –ø–∞–ø–∫–∏ —á–µ—Ä–µ–∑ huggingface_hub.
–ó–∞–º—ñ–Ω—ñ—Ç—å MODEL_ID_* –Ω–∞ –≤–∞—à—ñ —Ä–µ–∞–ª—å–Ω—ñ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—ó.
"""
from huggingface_hub import snapshot_download

# !!! –ó–ê–ú–Ü–ù–Ü–¢–¨ –Ω–∞ –≤–∞—à—ñ —Ä–µ–∞–ª—å–Ω—ñ ID —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—ó–≤ —É HF !!!
MODEL_ID_VERBALIZER = "ina-speech-research/Ukrainian-Verbalizer-g2p-v1"  # –ø—Ä–∏–∫–ª–∞–¥
MODEL_ID_STYLETTS2_SINGLE = "patriotyk/styletts2_ukrainian_single"         # –ø—Ä–∏–∫–ª–∞–¥
MODEL_ID_STYLETTS2_MULTI = "patriotyk/styletts2_ukrainian_multispeaker"    # –ø—Ä–∏–∫–ª–∞–¥

print("–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤–µ—Ä–±–∞–ª—ñ–∑–∞—Ç–æ—Ä‚Ä¶")
snapshot_download(repo_id=MODEL_ID_VERBALIZER, local_dir="models/models--verbalizer")

print("–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ StyleTTS2 single‚Ä¶")
snapshot_download(repo_id=MODEL_ID_STYLETTS2_SINGLE, local_dir="models/models--styletts2-single")

print("–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ StyleTTS2 multi‚Ä¶")
snapshot_download(repo_id=MODEL_ID_STYLETTS2_MULTI, local_dir="models/models--styletts2-multi")

print("–ì–æ—Ç–æ–≤–æ.")
```

### `.gitignore`
```
.venv/
__pycache__/
*.pt
*.wav
outputs/
models/
*.ipynb_checkpoints
.DS_Store
```

### `voices/README.md`
```markdown
# –ì–æ–ª–æ—Å–∏ –¥–ª—è multi-speaker StyleTTS2

–ü–æ–∫–ª–∞–¥—ñ—Ç—å —Å—é–¥–∏ —Å—Ç–∏–ª—ñ –≥–æ–ª–æ—Å—ñ–≤ —É —Ñ–æ—Ä–º–∞—Ç—ñ `.pt` (—Ç–µ–Ω–∑–æ—Ä–∏ –µ–º–±–µ–¥—ñ–Ω–≥—ñ–≤ —Å—Ç–∏–ª—é).

- –Ü–º º—è —Ñ–∞–π–ª—É = —ñ–º º—è –≥–æ–ª–æ—Å—É (–≤—ñ–¥–æ–±—Ä–∞–∂–∞—Ç–∏–º–µ—Ç—å—Å—è —É UI).
- –î–ª—è single-speaker —Ä–µ–∂–∏–º—É —Ü—è –ø–∞–ø–∫–∞ –Ω–µ –ø–æ—Ç—Ä—ñ–±–Ω–∞.
```

---

## üñ•Ô∏è `app.py` (–ø–æ–≤–Ω–∏–π)
```python
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

import glob
import re
import srt
import numpy as np
from datetime import datetime

# Gradio / Spaces
import gradio as gr
try:
    import spaces
    gpu_decorator = spaces.GPU
except Exception:  # —è–∫—â–æ –Ω–µ —É HF Spaces ‚Äì no-op –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä
    def gpu_decorator(fn):
        return fn

import torch
from unicodedata import normalize

from styletts2_inference.models import StyleTTS2
from ukrainian_word_stress import Stressifier, StressSymbol

from verbalizer import Verbalizer
from ipa_uk import ipa
from utils.text import split_to_parts, clean_and_stress, clean_sub_text
from utils.audio import (
    ensure_dir, save_wav, make_silence, normalize_audio, time_stretch_to_duration
)

# ================== –ö–û–ù–§–Ü–ì ==================
VERBALIZER_DIR = 'models/models--verbalizer'
STYLETTS2_SINGLE_DIR = 'models/models--styletts2-single'
STYLETTS2_MULTI_DIR = 'models/models--styletts2-multi'
PROMPTS_DIR = 'voices'
OUTPUTS_DIR = 'outputs'
SAMPLE_RATE = 24000

stressify = Stressifier()

device = 'cuda' if torch.cuda.is_available() else 'cpu'

# –í–µ—Ä–±–∞–ª—ñ–∑–∞—Ç–æ—Ä (–æ—Ñ–ª–∞–π–Ω)
verbalizer = Verbalizer(model_path=VERBALIZER_DIR, device=device)

# ======== –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π StyleTTS2 ========
# single
single_model = StyleTTS2(hf_path=STYLETTS2_SINGLE_DIR, device=device)
# —Å—Ç–∏–ª—å single ‚Äì –æ–∫—Ä–µ–º–∏–π .pt –∞–±–æ –≤–∑—è—Ç–∏–π —ñ–∑ –º–æ–¥–µ–ª—ñ; –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç–∏ –≤—Å—Ç–∞–Ω–æ–≤–∏–º–æ None
single_style = None

# multi
multi_model = StyleTTS2(hf_path=STYLETTS2_MULTI_DIR, device=device)

# —Å—Ç–∏–ª—ñ –≥–æ–ª–æ—Å—ñ–≤ (pt) —ñ–∑ –ø–∞–ø–∫–∏ voices/
multi_styles = {}
prompts_list = sorted(glob.glob(os.path.join(PROMPTS_DIR, '*.pt')))
prompts_list = [os.path.splitext(os.path.basename(p))[0] for p in prompts_list]
for name in prompts_list:
    path = os.path.join(PROMPTS_DIR, f'{name}.pt')
    try:
        multi_styles[name] = torch.load(path, map_location=device)
        print('[voices] loaded', name)
    except Exception as e:
        print('[voices] fail', name, e)

models = {
    'multi': { 'model': multi_model, 'styles': multi_styles },
    'single': { 'model': single_model, 'style': single_style }
}

# ================== –§–£–ù–ö–¶–Ü–û–ù–ê–õ ==================
@gpu_decorator
@torch.inference_mode()
def verbalize_ui(text: str) -> str:
    parts = split_to_parts(text)
    out = []
    for p in parts:
        if p.strip():
            out.append(verbalizer.generate_text(p))
    return ' '.join(out)


@gpu_decorator
@torch.inference_mode()
def synthesize(model_name: str, text: str, speed: float, voice_name: str | None = None, progress=gr.Progress()):
    if not text or text.strip() == "":
        raise gr.Error("–í–≤–µ–¥—ñ—Ç—å —Ç–µ–∫—Å—Ç")
    if len(text) > 50000:
        raise gr.Error("–¢–µ–∫—Å—Ç –º–∞—î –±—É—Ç–∏ < 50k —Å–∏–º–≤–æ–ª—ñ–≤")

    result_wav = []
    model_data = models[model_name]

    for t in progress.tqdm(split_to_parts(text)):
        t = t.strip().replace('"', '')
        if not t:
            continue
        t = clean_and_stress(t)
        t = verbalizer.generate_text(t)
        ps = ipa(t)

        tokens = model_data['model'].tokenizer.encode(ps)
        style = None
        if model_name == 'multi' and voice_name:
            style = model_data['styles'].get(voice_name)
        elif model_name == 'single':
            style = model_data.get('style')

        wav = model_data['model'](tokens, speed=speed, s_prev=style)
        wav = normalize_audio(wav)
        result_wav.append(wav)

    if not result_wav:
        raise gr.Error("–ü–æ—Ä–æ–∂–Ω—ñ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")

    final_audio = torch.cat(result_wav).cpu().numpy().astype('float32')
    # –∞–≤—Ç–æ–∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
    fname = save_wav(final_audio, SAMPLE_RATE, OUTPUTS_DIR, base='tts')
    return (SAMPLE_RATE, final_audio), fname


@gpu_decorator
@torch.inference_mode()
def synthesize_subtitles(sub_file, model_name: str, speed: float, voice_name: str | None = None,
                         strict_timing: bool = True, elasticity: float = 0.35,
                         progress=gr.Progress()):
    """
    –û–∑–≤—É—á–∫–∞ SRT. –î–ª—è –∫–æ–∂–Ω–æ—ó —Ä–µ–ø–ª—ñ–∫–∏:
      1) –≤–µ—Ä–±–∞–ª—ñ–∑–∞—Ü—ñ—è ‚Üí –Ω–∞–≥–æ–ª–æ—Å ‚Üí IPA
      2) —Å–∏–Ω—Ç–µ–∑ StyleTTS2
      3) time-stretch –ø—ñ–¥ —Ç—Ä–∏–≤–∞–ª—ñ—Å—Ç—å (–∑–∞ –ø–æ—Ç—Ä–µ–±–∏)
      4) —Ç–∏—à–∞ –º—ñ–∂ —Ä–µ–ø–ª—ñ–∫–∞–º–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ –¥–æ —Ç–∞–π–º—ñ–Ω–≥—ñ–≤
    –ü–∞—Ä–∞–º–µ—Ç—Ä elasticity –≤–∏–∑–Ω–∞—á–∞—î –º–µ–∂—ñ time-stretch: rate ‚àà [1‚àíel, 1+el].
    """
    if sub_file is None:
        raise gr.Error("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ .srt —Ñ–∞–π–ª")

    with open(sub_file.name, 'r', encoding='utf-8') as f:
        subs = list(srt.parse(f.read()))

    if not subs:
        raise gr.Error("–ü–æ—Ä–æ–∂–Ω—ñ —Å—É–±—Ç–∏—Ç—Ä–∏")

    model_data = models[model_name]
    cur_t = 0.0
    chunks: list[torch.Tensor] = []

    low = max(0.2, 1.0 - elasticity)
    high = 1.0 + elasticity

    for sub in progress.tqdm(subs):
        start_sec = sub.start.total_seconds()
        end_sec = sub.end.total_seconds()
        duration = max(0.0, end_sec - start_sec)

        # —Ç–∏—à–∞ –¥–æ –ø–æ—á–∞—Ç–∫—É, —è–∫—â–æ —î —Ä–æ–∑—Ä–∏–≤
        if start_sec > cur_t:
            chunks.append(make_silence(start_sec - cur_t, SAMPLE_RATE))
            cur_t = start_sec

        # –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç—É
        raw = clean_sub_text(sub.content)
        if not raw:
            continue
        t = clean_and_stress(raw)
        t = verbalizer.generate_text(t)
        ps = ipa(t)

        # —Å–∏–Ω—Ç–µ–∑
        tokens = model_data['model'].tokenizer.encode(ps)
        style = None
        if model_name == 'multi' and voice_name:
            style = model_data['styles'].get(voice_name)
        elif model_name == 'single':
            style = model_data.get('style')

        wav = model_data['model'](tokens, speed=speed, s_prev=style)
        wav = normalize_audio(wav)
        np_wav = wav.cpu().numpy().astype('float32')

        # –ø—ñ–¥–≥—ñ–Ω —É —á–∞—Å
        if strict_timing and duration > 0:
            np_wav = time_stretch_to_duration(np_wav, SAMPLE_RATE, duration, clamp=(low, high))
        # –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –¥–æ torch –¥–ª—è —É–Ω—ñ—Ñ—ñ–∫–∞—Ü—ñ—ó
        wav = torch.from_numpy(np_wav)
        chunks.append(wav)

        cur_t = end_sec

    if not chunks:
        raise gr.Error("–ù–µ–º–∞—î –∞—É–¥—ñ–æ –¥–ª—è –∑–±–∏—Ä–∞–Ω–Ω—è")

    final = torch.cat(chunks).cpu().numpy().astype('float32')

    base = os.path.splitext(os.path.basename(sub_file.name))[0]
    fname = save_wav(final, SAMPLE_RATE, OUTPUTS_DIR, base=f'subdub__{base}')

    return (SAMPLE_RATE, final), fname


# ================== UI ==================
with gr.Blocks(title="UA-TTS-Subdub", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üá∫üá¶ UA‚ÄëTTS‚ÄëSubdub ‚Äî StyleTTS2 + –í–µ—Ä–±–∞–ª—ñ–∑–∞—Ü—ñ—è + SRT –æ–∑–≤—É—á–∫–∞")

    with gr.Tab("–¢–µ–∫—Å—Ç ‚Üí –ú–æ–≤–∞"):
        with gr.Row():
            model_select = gr.Dropdown(choices=["multi", "single"], value="multi", label="–ú–æ–¥–µ–ª—å")
            voice_select = gr.Dropdown(choices=sorted(list(multi_styles.keys())), value=None, label="–ì–æ–ª–æ—Å (multi)")
            speed_slider = gr.Slider(0.5, 2.0, value=1.0, step=0.05, label="–®–≤–∏–¥–∫—ñ—Å—Ç—å")
        text_in = gr.Textbox(lines=6, label="–¢–µ–∫—Å—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é")
        with gr.Row():
            btn_verbal = gr.Button("–í–µ—Ä–±–∞–ª—ñ–∑—É–≤–∞—Ç–∏")
            btn_synth = gr.Button("–°–∏–Ω—Ç–µ–∑—É–≤–∞—Ç–∏")
        audio_out = gr.Audio(label="–†–µ–∑—É–ª—å—Ç–∞—Ç", type="numpy")
        file_out = gr.File(label="–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ .wav")

        btn_verbal.click(fn=verbalize_ui, inputs=[text_in], outputs=[text_in])
        btn_synth.click(fn=synthesize,
                        inputs=[model_select, text_in, speed_slider, voice_select],
                        outputs=[audio_out, file_out])

    with gr.Tab("–û–∑–≤—É—á–∫–∞ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤"):
        sub_file = gr.File(label="–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ .srt", file_types=['.srt'])
        with gr.Row():
            model_select2 = gr.Dropdown(choices=["multi", "single"], value="multi", label="–ú–æ–¥–µ–ª—å")
            voice_select2 = gr.Dropdown(choices=sorted(list(multi_styles.keys())), value=None, label="–ì–æ–ª–æ—Å (multi)")
            speed_slider2 = gr.Slider(0.5, 2.0, value=1.0, step=0.05, label="–®–≤–∏–¥–∫—ñ—Å—Ç—å")
        with gr.Row():
            strict = gr.Checkbox(value=True, label="–°—Ç—Ä–æ–≥–æ –ø—ñ–¥–≥–∞–Ω—è—Ç–∏ –ø—ñ–¥ —Ç–∞–π–º—ñ–Ω–≥–∏ (time‚Äëstretch)")
            elasticity = gr.Slider(0.2, 0.6, value=0.35, step=0.05, label="–ï–ª–∞—Å—Ç–∏—á–Ω—ñ—Å—Ç—å time‚Äëstretch (¬±)")
        btn_sub = gr.Button("–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –æ–∑–≤—É—á–∫—É —Å—É–±—Ç–∏—Ç—Ä—ñ–≤")
        audio_out2 = gr.Audio(label="–†–µ–∑—É–ª—å—Ç–∞—Ç", type="numpy")
        file_out2 = gr.File(label="–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ .wav")

        btn_sub.click(fn=synthesize_subtitles,
                      inputs=[sub_file, model_select2, speed_slider2, voice_select2, strict, elasticity],
                      outputs=[audio_out2, file_out2])

if __name__ == "__main__":
    ensure_dir(OUTPUTS_DIR)
    demo.queue(api_open=True, max_size=15).launch(show_api=True)
```

---

## üìí README.md (—Å–∫–æ—Ä–æ—á–µ–Ω–∞ –∫–æ–ø—ñ—è)
```markdown
# UA-TTS-Subdub

–£–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω–∏–π –æ—Ñ–ª–∞–π–Ω TTS-–∫–æ–Ω–≤–µ—î—Ä –Ω–∞ –±–∞–∑—ñ StyleTTS2 —ñ–∑ –≤–µ—Ä–±–∞–ª—ñ–∑–∞—Ü—ñ—î—é, –Ω–∞–≥–æ–ª–æ—Å–∞–º–∏ —Ç–∞ –ø–æ–≤–Ω–æ—é –æ–∑–≤—É—á–∫–æ—é SRT –∑ –¥–æ—Ç—Ä–∏–º–∞–Ω–Ω—è–º —Ç–∞–π–º—ñ–Ω–≥—ñ–≤ (time‚Äëstretch).

## –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
python scripts/download_models.py   # (–æ–ø—Ü—ñ–π–Ω–æ) –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç—å –º–æ–¥–µ–ª—ñ —É models/
python app.py
```
–í—ñ–¥–∫—Ä–∏–π—Ç–µ http://127.0.0.1:7860

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞
- `app.py` ‚Äî Gradio UI, TTS —ñ SRT-–æ–∑–≤—É—á–∫–∞
- `verbalizer.py` ‚Äî mBART –≤–µ—Ä–±–∞–ª—ñ–∑–∞—Ç–æ—Ä (–æ—Ñ–ª–∞–π–Ω)
- `ipa_uk.py` ‚Äî –∞–¥–∞–ø—Ç–∏–≤–Ω–∏–π G2P —É IPA
- `utils/` ‚Äî –∞—É–¥—ñ–æ/—Ç–µ–∫—Å—Ç —É—Ç–∏–ª—ñ—Ç–∏
- `voices/` ‚Äî —Å—Ç–∏–ª—ñ .pt –¥–ª—è multi-speaker
- `models/` ‚Äî –ª–æ–∫–∞–ª—å–Ω—ñ —Å–Ω–∞–ø—à–æ—Ç–∏ –º–æ–¥–µ–ª–µ–π
- `outputs/` ‚Äî –≥–æ—Ç–æ–≤—ñ .wav

## –ú–æ–¥–µ–ª—ñ
–í–∫–∞–∂—ñ—Ç—å –ª–æ–∫–∞–ª—å–Ω—ñ —à–ª—è—Ö–∏ —É –≤–µ—Ä—Ö—ñ–≤—Ü—ñ `app.py` –∞–±–æ —Å–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ—Å—å `scripts/download_models.py` –π –∑–∞–º—ñ–Ω—ñ—Ç—å `MODEL_ID_*` –Ω–∞ –≤–∞—à—ñ —Ä–µ–∞–ª—å–Ω—ñ HF‚Äë—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä—ñ—ó.

## –û–∑–≤—É—á–∫–∞ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤
- –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ `.srt` —É –≤–∫–ª–∞–¥—Ü—ñ ¬´–û–∑–≤—É—á–∫–∞ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤¬ª.
- –°–∏—Å—Ç–µ–º–∞ —Å–∏–Ω—Ç–µ–∑—É—î –∫–æ–∂–Ω—É —Ä–µ–ø–ª—ñ–∫—É —Ç–∞ –ø—ñ–¥–∂–µ–Ω–µ —ó—ó –≤ —á–∞—Å –ø—ñ–¥ —Ç–∞–π–º—ñ–Ω–≥–∏ (–æ–ø—Ü—ñ–π–Ω–æ –º–æ–∂–Ω–∞ –ø–æ—Å–ª–∞–±–∏—Ç–∏ –∂–æ—Ä—Å—Ç–∫—ñ—Å—Ç—å —á–µ—Ä–µ–∑ ¬´–ï–ª–∞—Å—Ç–∏—á–Ω—ñ—Å—Ç—å¬ª).
- –ü–∞—É–∑–∞ –º—ñ–∂ —Ä–µ–ø–ª—ñ–∫–∞–º–∏ —Å—Ç–≤–æ—Ä—é—î—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ.
- –†–µ–∑—É–ª—å—Ç–∞—Ç –∑–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ `outputs/` —ñ –¥–æ—Å—Ç—É–ø–Ω–∏–π –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è.

## –õ—ñ—Ü–µ–Ω–∑—ñ—è –º–æ–¥–µ–ª–µ–π
–ü–µ—Ä–µ–∫–æ–Ω–∞–π—Ç–µ—Å—å, —â–æ –ª—ñ—Ü–µ–Ω–∑—ñ—ó –º–æ–¥–µ–ª–µ–π –¥–æ–∑–≤–æ–ª—è—é—Ç—å –ª–æ–∫–∞–ª—å–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è/–ø–µ—Ä–µ—Ä–æ–∑–ø–æ–≤—Å—é–¥–∂–µ–Ω–Ω—è.
```

---

## üß™ –ü—Ä–∏–º—ñ—Ç–∫–∏ —Ç–∞ –ø–æ—Ä–∞–¥–∏
- –Ø–∫—â–æ —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ç–æ—Ä/–º–æ–¥–µ–ª—å StyleTTS2 –æ—á—ñ–∫—É—î —ñ–Ω—à–∏–π —Ñ–æ—Ä–º–∞—Ç —Ñ–æ–Ω–µ–º ‚Äî –∑–∞–º—ñ–Ω—ñ—Ç—å `ipa_uk.py` –Ω–∞ –≤–∞—à —Ç–æ—á–Ω–∏–π G2P.
- –Ø–∫—â–æ –ø—Ä–∞—Ü—é—î—Ç–µ **–Ω–µ —É HF Spaces**, —ñ–º–ø–æ—Ä—Ç `spaces` –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å—Ç–∞—î no‚Äëop.
- –î–ª—è **—ñ–¥–µ–∞–ª—å–Ω–æ—ó —Å–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—ó** –∑ –≤—ñ–¥–µ–æ–º–æ–Ω—Ç–∞–∂–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥—É—î–º–æ –µ–∫—Å–ø–æ—Ä—Ç—É–≤–∞—Ç–∏ `.wav`, –∞ –¥–∞–ª—ñ –∑–≤–æ–¥–∏—Ç–∏ —É –≤—ñ–¥–µ–æ—Ä–µ–¥–∞–∫—Ç–æ—Ä—ñ —á–∏ —á–µ—Ä–µ–∑ `ffmpeg`.
- –Ø–∫—â–æ –≤–∞—à—ñ —Å—É–±—Ç–∏—Ç—Ä–∏ –º–∞—é—Ç—å –ø–µ—Ä–µ–∫—Ä–∏—Ç—Ç—è —Ç–∞–π–º—ñ–Ω–≥—ñ–≤, —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ—Å—Ç–æ –Ω–µ –≤—Å—Ç–∞–≤–ª—è—Ç–∏–º–µ —Ç–∏—à—É; –º—ñ–∫—Å—É–≤–∞–Ω–Ω—è –ø–µ—Ä–µ–∫—Ä–∏—Ç–∏—Ö —Ä–µ–ø–ª—ñ–∫ —Ç—É—Ç –Ω–µ –≤–∏–∫–æ–Ω—É—î—Ç—å—Å—è (–º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –ø—Ä–∏ –ø–æ—Ç—Ä–µ–±—ñ).

---

## ‚úÖ –ì–æ—Ç–æ–≤–æ!
–¶–µ –ø–æ–≤–Ω–∏–π –∫—ñ—Å—Ç—è–∫ –ø—Ä–æ–¥–∞–∫—à–Ω‚Äë—Ä—ñ–≤–Ω—è –¥–ª—è —É–∫—Ä–∞—ó–Ω–æ–º–æ–≤–Ω–æ–≥–æ –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è —Ç–µ–∫—Å—Ç—É —Ç–∞ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤ —ñ–∑ –º–æ–∂–ª–∏–≤—ñ—Å—Ç—é –æ—Ñ–ª–∞–π–Ω‚Äë—Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è. –ó–∞–º—ñ–Ω—ñ—Ç—å/—É—Ç–æ—á–Ω—ñ—Ç—å –ª–∏—à–µ —Ä–µ–∞–ª—å–Ω—ñ —à–ª—è—Ö–∏ –¥–æ –º–æ–¥–µ–ª–µ–π —ñ G2P –∑–∞ –≤–∞—à–∏–º–∏ –≤–∏–º–æ–≥–∞–º–∏.

